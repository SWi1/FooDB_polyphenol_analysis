---
title: "04_FooDB_FNDDSFullMatch"
author: "Stephanie Wilson"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

# Matching FooDB to ASA24 Ingredient Descriptions
## Step 4: Matching ASA24 to FooDB 
### Part 1: Ingredient Code Matching

__Required Input Files__
  - *FooDB_V2_descripcleaned.csv* - Output from 02_FooDB_TextProcessing
  - *asa_descripcleaned.csv* - Output from 02_FooDB_TextProcessing
  
__Information__
This script looks for ingredient code matches between ASA24 and FooDB. FooDB includes original source id's which makes this possible. For items that have multiple hits, this code will find the most similar FooDB ingredient description. This code also identifies what codes did not match to FooDB and will need further downstream processing. Specifically, this code:

  1) Checks matches with ASA's ingredient_subcode to FooDB's orig_food_id
  2) Consolidates Duplicate Code Matches in ASA24 to FooDB
     2a) Text Similarity Analysis and Filtering for Closest Match
     2b) Add in correct descriptions for formerly duplicated IDs
  
__Output__
  - *asa_descripcleaned_codematched.csv* - Includes all cleaned ASA24 ingredient descriptions including FoodB ingredient code matches + those that did not have a match
  - *missing_foodb_descrip.csv* - Just the ASA24 ingredient descriptions with no ingredient code match to FooDB
  

```{r Load packages, include= FALSE, warning=FALSE, message=FALSE}
library(tidyverse); library(stringdist)
```

```{r Load Data, include=FALSE}
Food_V2 = read.csv("FooDB/Food_V2_descripcleaned.csv", header=TRUE) %>%
  select(-c('source_type')) %>%
  mutate(orig_food_id = as.numeric(orig_food_id))

#Obtain unique codes
asa = read.csv('data/asa_descripcleaned.csv', header=TRUE) %>%
  distinct(Ingredient_description, .keep_all = TRUE)
#We have 1199 unique observation codes
```


### 1) Check matches with ASA's ingredient_subcode to FooDB's orig_food_id

```{r Check potential hits with orig_food_id, warning = FALSE}
#Left join with keep = TRUE to maintain both join keys in output
hits1 = left_join(asa, Food_V2, by = c('Ingredient_code' ='orig_food_id'),
                  keep=TRUE) %>%
  select(c(Ingredient_code, Ingredient_description, orig_food_id, 
           orig_food_common_name, food_V2_ID))
```


### 2) Consolidate Duplicates
The same ASA code may have multiple hits on FooDB when matched by food ids.

```{r Pull out duplicated subcodes for text similarity analysis}
duplicates = hits1 %>% 
  group_by(Ingredient_code) %>% 
  filter(n()>1) #Any code with more than 1 entry is filtered IN
```


### 2a) Text Similarity Analysis

Let us create a function to examine the similarity of two columns of two data with strings. We will use multiple text similarity metrics accepted by the _stringsim()_ function in the _stringdist_ package.

```{r Create function to examine text similarity metrics}
sim_score <- function(x, asa_descrip, foodb_descrip){
  metric = x #where x is a list of text similarity metrics accepted by stringsim
  asa_descrip = asa_descrip #df column of descriptions
  foodb_descrip = foodb_descrip #df column of descriptions
  output = data.frame(matrix(ncol=length(metric), nrow=length(asa_descrip)))
  
for(i in seq_along(metric)){ #run similarity for each metric
  output[[i]] = stringsim(asa_descrip, foodb_descrip, 
                          method = metric[[i]], p = 0.1)
}
  colnames(output) = metric # rename column names
  output = output %>% add_column(asa_descrip, foodb_descrip) %>% # add columns
    relocate(asa_descrip, foodb_descrip) # relocate descriptions to front
  return(output)
}
```


```{r Run function to calculate multiple text similarity scores, warning = FALSE}
scores_auto = sim_score(x = c("osa", "lv", "dl", "hamming", "lcs", 
                              "qgram", "cosine", "jaccard", "jw", "soundex"), 
                        asa_descrip = duplicates$Ingredient_description, 
                        foodb_descrip = duplicates$orig_food_common_name)
```


```{r Calculate average text similarity score}
#Create new column with average similiarity score
#scores closest to 1 indicate most similar
#Remove food description info columns prior to merging.
scores_auto = scores_auto %>%
  mutate(scores_auto, mean_score = 
           rowMeans(select(scores_auto, 
                           c(osa, lv, dl, hamming, lcs, qgram, cosine, jaccard, 
                             jw, soundex)))) %>%
  select(-c(asa_descrip, foodb_descrip))
```


```{r Merge Dataframes}
duplicates = cbind(duplicates, scores_auto) 
```


```{r Filter in the highest similarity scores for each conflict}
duplicates_resolved = duplicates %>%
  group_by(Ingredient_code) %>% 
  filter(mean_score==max(mean_score)) 

#Confirm that we've resolved the correct number of duplicate codes codes 
length(unique(duplicates$Ingredient_code)) == length(unique(duplicates_resolved$Ingredient_code))
```

### 2b) Add in correct descriptions for formerly duplicated IDs
```{r Filter out duplicates & add replacements, message = FALSE}
# Filter Out duplicates
asa = hits1 %>% 
  group_by(Ingredient_code) %>% 
  filter(!n()>1) 

#Prepare replacements, Remove score columns in duplicates_resolved
duplicates_resolved = duplicates_resolved[ ,1:5]
```


```{r Add back in text-matched codes, message = FALSE}
# Number of observations should add to 1199 (# of distinct codes in the ASA file).
asa = full_join(asa, duplicates_resolved)

write.csv(asa, 'data/asa_descripcleaned_codematched.csv', row.names = FALSE)
```


```{r What is missing}
#How many codes still need to be matched?
table(is.na(asa$orig_food_id))

missing = asa %>%
  filter(is.na(orig_food_common_name))
```

We will match the remaining 170 codes in Part II of the matching script and export what we have for now.




