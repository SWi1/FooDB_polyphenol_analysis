{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b67ec4ae-aa56-4c5f-bf9b-cc229bfb3e39",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# Matching FooDB to ASA24 Ingredient Descriptions\n",
    "## Step 3: Cleaning FoodB and ASA Descriptions\n",
    "\n",
    "__Required Input Files__\n",
    "\n",
    "  - **Content_updated.csv** - Output from 02_FooDB_FoodBCleaning\n",
    "  - **asa_recode_remapped10202022.csv** - Output from 03_ingredientize_code_remap.rmd script\n",
    "  - **ingredientized_asa_10-2022.csv** - Output from 04_ingredientize_merge.rmd script\n",
    "\n",
    "__Information__  \n",
    "This script prepares food descriptions in FoodB's Content.csv and in the ASA dietary data for downstream text similarity comparisons. This script specifically achieves the following:\n",
    "    \n",
    "    1) Create a new list of distinct food descriptions in FooDB.\n",
    "    2) Resolves Word Cases\n",
    "    3) Removes certain punctuation\n",
    "    4) Identifies candidates for stop word removal and removes them\n",
    "    5) Lemmatize text descriptions\n",
    "    6) Exports cleaned food descriptions from FoodB and ASA\n",
    "        - Output: Food_V2_updated_descripcleaned.csv\n",
    "        - Output: asa_descripcleaned.csv\n",
    "        - Output: remap_descrip_cleaned.csv\n",
    "        \n",
    "__Output__\n",
    "  - Food_V2_descripcleaned.csv\n",
    "  - asa_descripcleaned.csv\n",
    "  - remap_descrip_cleaned.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d46681-4ed7-4a1d-8ecf-c435dd503bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e36563c-1027-4cc9-a314-8b78a77d94b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/stephanie.wilson/Desktop/SYNC/Scripts/FooDB_FNDDS'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure working directory is the project folder\n",
    "mapping = os.getcwd()\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d869dfc0-d16f-418f-8663-268aeb0e5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "remap = pd.read_csv('Ingredientize/data/ingred_recode_remapped10202022.csv')\n",
    "asa = pd.read_csv('Ingredientize/data/ingredientized_asa_10-2022.csv')\n",
    "Content = pd.read_csv('FooDB/Content_updated.csv.bz2', compression='bz2', low_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea86dab2-d9af-44ff-8692-166afb1e1c69",
   "metadata": {},
   "source": [
    "###  1) Create a new list of distinct food descriptions in FooDB.\n",
    "\n",
    "Recall the original FooDB Food.csv contains ~900 unique food descriptions. Content.csv has _many_ more food descriptions than Food.csv. Content.csv technically lists x number of compounds and their amounts per each food description. Thus, there are duplicate food descriptions. We need to filter in unique food names. Luckily, we already have a unique food descriptor for each of these unique food names from 01_FooDB_FNDDS_FooDBCleaning.ipynb.\n",
    "\n",
    "  - Note: Food.csv has 992 descriptions. Food_updated.csv has 993 with the addition of Code 554 from 01_FoodBCleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7d57c-af44-47df-8e9a-bef6c4ba31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the Content Frame\n",
    "Food_V2 = Content.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f2da5-b0dc-4f77-8bc2-e119bcdc1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unneeded columns\n",
    "Food_V2.drop(columns=['creator_id', 'updater_id', 'orig_citation', \\\n",
    "    'created_at', 'updated_at', 'orig_method', 'orig_unit_expression', \\\n",
    "        'citation_type', 'orig_content', 'standard_content', \\\n",
    "            'orig_content', 'orig_min', 'orig_max', 'orig_unit'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2979b4d-89b1-458f-a8b4-d912c4c4a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct food descriptions are there in FooDB?\n",
    "print(Food_V2['orig_food_common_name'].value_counts().shape[0], ' Unique food entries in FooDB Content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14949954-e92a-48ae-86c3-9762d411d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate food names\n",
    "Food_V2 = Food_V2.drop_duplicates(subset = 'orig_food_common_name')\n",
    "Food_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088611e0-68cf-4e3c-acf0-7388d4e07fc9",
   "metadata": {},
   "source": [
    "### 2) Resolve Word Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ae360-baa9-49a9-aba4-c26378e9716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate food description columns & convert into series\n",
    "asa_descrip = asa['Ingredient_description'].squeeze()\n",
    "Food_V2_descrip = Food_V2['orig_food_common_name'].squeeze()\n",
    "remap_descrip = remap['Ingredient_description_y'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd8022-b2bf-4b56-b762-4fe963b985a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert series to lowercase\n",
    "#Add c designation to specify food descriptions are now cleaned\n",
    "asa_descrip_c = asa_descrip.str.lower()\n",
    "Food_V2_descrip_c = Food_V2_descrip.str.lower()\n",
    "remap_descrip_c = remap_descrip.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b888b-97b9-4270-a4a3-e89f30ca2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that data is lowercase\n",
    "asa_descrip_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63773d-c08a-4bec-93c1-185449cf3cb1",
   "metadata": {},
   "source": [
    "### 3) Remove certain punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of punctuation to remove and their respective replacements\n",
    "punctuation = {',': '', '-': ' ', '(': '', ')': '', ':': ' ', ';' : ' ', '%': ''} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8af2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation in Food_V2 descriptions\n",
    "for x, y in punctuation.items():\n",
    "    Food_V2_descrip_c = Food_V2_descrip_c.str.replace(x, y, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8af2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation in Food_V2 descriptions\n",
    "for x, y in punctuation.items():\n",
    "    asa_descrip_c = asa_descrip_c.str.replace(x, y, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation in Food_V2 descriptions\n",
    "for x, y in punctuation.items():\n",
    "    remap_descrip_c = remap_descrip_c.str.replace(x, y, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9bd00-4b17-4ec6-a6a0-ae2ae87f3c33",
   "metadata": {},
   "source": [
    "__Remove Numbers__  \n",
    "Numbers in this case are important to identify foods (ie, 5% vs 20% fat ground beef), so making the decision to not remove numbers\n",
    "\n",
    "### 4) Identify candidates for stop word removal and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf899d10-c015-4e67-96b9-591ca5ceae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse series into a string of words, then remove extra spaces\n",
    "Food_V2_string = Food_V2_descrip_c.str.cat(sep = ' ')\n",
    "asa_string = asa_descrip_c.str.cat(sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de924708-6005-4b60-ab86-4248a71ecd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm column is collapsed\n",
    "asa_string[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9aff0",
   "metadata": {},
   "source": [
    "Stop word removal in Food_V2 can also be applied toward Content.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa1bf8-5145-41e3-9852-ce12dd9b0109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the string into a list of words\n",
    "asa_string = asa_string.split()\n",
    "Food_V2_string = Food_V2_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96319cf4-64e5-40a0-b2a9-defeb6150c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count word occurence which helps identify candidates for stop words\n",
    "Food_V2_counts = pd.Series(Food_V2_string).value_counts(dropna=False)\n",
    "pd.DataFrame(Food_V2_counts, columns = ['COUNTS']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c090f-1ad5-4402-93f1-4893bb9bc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count word occurence which helps identify candidates for stop words\n",
    "asa_counts = pd.Series(asa_string).value_counts(dropna=False)\n",
    "pd.DataFrame(asa_counts, columns = ['COUNTS']).head(40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a76a45f5-fea5-4cc5-8d48-6f602dd1ea3a",
   "metadata": {},
   "source": [
    "Stop words based off frequently occurring words in asa and FooDB:\n",
    "  - and\n",
    "  - to\n",
    "  - in\n",
    "  - or\n",
    "  - as\n",
    "  - food\n",
    "  - foods\n",
    "  - distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a0873-9ba8-41e7-bb5f-23a4d49f02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stop words and their respective replacements\n",
    "# Spaces added to stop words to avoid removing stop words that technically occur within another word. \n",
    "stopwords = {' and ': ' ', ' to ': ' ', ' in ': ' ', ' or ': ' ', ' as ': ' ', \\\n",
    "    ' food ': ' ', ' foods ': ' ', ' distribution ': ' '} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223616b-2a87-4816-9bad-c0c9b13f1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words in Food_V2 descriptions\n",
    "for x, y in stopwords.items():\n",
    "    Food_V2_descrip_c = Food_V2_descrip_c.str.replace(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d1389-edaf-4d98-851f-098e3d59ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words in ASA descriptions\n",
    "for x, y in stopwords.items():\n",
    "    asa_descrip_c = asa_descrip_c.str.replace(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words in ASA descriptions\n",
    "for x, y in stopwords.items():\n",
    "    remap_descrip_c = remap_descrip_c.str.replace(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97994c5-3fdb-4b3e-b227-00c081584797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found an additional replacement while comparing strings\n",
    "#Replace w/o to without in FooDB, not present in asa\n",
    "Food_V2_descrip_c = Food_V2_descrip_c.str.replace('w/o', 'without')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c32dce",
   "metadata": {},
   "source": [
    "### 5) Lemmatize text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e53db0-4d6f-49e2-b45c-b43a477b5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace original food descriptions with the cleaned descriptions\n",
    "asa['Ingredient_description'] = asa_descrip_c\n",
    "Food_V2['orig_food_common_name'] = Food_V2_descrip_c\n",
    "remap['Ingredient_description_y'] = remap_descrip_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lemmatize function\n",
    "def lemmatize_text(text):\n",
    "    text = \"\".join([word for word in text if word])\n",
    "    tokens = re.split('[-\\W+]', text)\n",
    "    text = [wn.lemmatize(word) for word in tokens]\n",
    "    return set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92125f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asa['Ingredient_descrip_lemmatized'] = asa['Ingredient_description'].apply(lambda x: lemmatize_text(x.lower()))\n",
    "Food_V2['orig_food_common_name_lemmatized'] = Food_V2['orig_food_common_name'].apply(lambda x: lemmatize_text(x.lower()))\n",
    "remap['Ingredient_descrip_y_lemmatized'] = remap['Ingredient_description_y'].apply(lambda x: lemmatize_text(x.lower()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa39662d-a5f0-4744-bdc9-50bbd9289d06",
   "metadata": {},
   "source": [
    "### 6) Export cleaned food descriptions from FoodB and asa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799373e-6f54-42fe-b23d-84f74a8d3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Cleaned Food Descriptions\n",
    "Food_V2.to_csv('FooDB/Food_V2_descripcleaned.csv', index = None, header = True)\n",
    "asa.to_csv('data/asa_descripcleaned.csv', index = None, header = True)\n",
    "remap.to_csv('data/remap_descripcleaned.csv', index = None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (v3.10.6:9c7b4bd164, Aug  1 2022, 17:13:48) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
